{"cells":[{"cell_type":"markdown","metadata":{"id":"avn_OMFPmBel"},"source":["# Scripting languages: Assignment 2\n","\n","Deadline: Wednesday 29 November 2023, 11:59pm\n","\n","You are required to submit this assignment in notebook format (`.ipynb`). If you're using Jupyter Notebook on your own computer, this file will be created automatically. If you're using Google Colab, you can create an `.ipynb` file by selecting File -> Download -> Download .ipynb.\n","\n","You are encouraged to use (an appropriate amount of) comments in order to explain what your code is doing, or to make use of the notebook text blocks in order to do so.\n","\n","You can upload your file on Toledo (under 'Assignments'\n","$\\rightarrow$ 'Assignment 3'). The deadline for submission is **Wednesday 29 November 2023, 11:59pm**."]},{"cell_type":"markdown","metadata":{"id":"JnAt5FC8-nni"},"source":["## Exercise 1: a `TextAnalysis` class\n","\n","Create a `TextAnalysis` class, that computes a number of text statistics for a given document (plain txt-file). Make sure your class has the following functionality:\n","\n","* your class can be initialized using a file location; upon initialization, your class will read the document from the file location, and will make sure it is properly preprocessed (segmented into sentences and tokenized);\n","\n","* your class has a method `average_word_length`, which computes the average length of words (i.e. average number of characters per word) in the document;\n","\n","* your class has a method `type_token_ratio`, which computes the total number of **unique** words (types) divided by the total number of words (tokens) in the document. As an example, the phrase *the dog and the cat and the man* contains 5 types and 8 tokens (and its type token ratio is thus 5/8);\n","\n","* you class has a method `hapax_ratio`, which computes the number of words occurring exactly once (i.e. [hapax legomena](https://en.wikipedia.org/wiki/Hapax_legomenon)) divided by the total number of words;\n","\n","* your class has a method `average_sentence_length`, which computes the average number of words per sentence in the document;\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9ixeLaHc8-6"},"outputs":[],"source":["#Must import nltk in order to operate nltk.word_tokenize() and nltk.sent_tokenize().\n","import nltk\n","\n","\n","#Establishing class and initialization\n","class TextAnalysis:\n","    def __init__(self, filename):\n","        self.filename = filename\n","        self.text_read = self.read_text()\n","        self.tokenized_text = self.tokenize_and_filter()\n","        self.preprocessed_text = self.preprocess()\n","\n","\n","    #Defining (3) methods that will be executed when the object is instantiated.\n","    def read_text(self):\n","        with open(self.filename, 'rt' , encoding='utf8') as infile:\n","            return infile.read()\n","            #Opens and reads the given file.\n","\n","    def tokenize_and_filter(self):\n","        return [token.lower() for token in nltk.word_tokenize(self.text_read) if token not in \".,?!:;()[]''``*\"]\n","        #Returns one large list that contains all the tokens (in lowercase form) of the given file minus punctuation.\n","        #Note that certains words (such as \"we'll\") will return as two separate tokens.\n","\n","    def preprocess(self):\n","        sentences = nltk.sent_tokenize(self.text_read) #separates sentences, but capitalization/punctuation remains.\n","        preprocessed_sentences = [] #list where \"cleaned\" sentences (no capitalization, no punctuation) will be looped into.\n","        for sent in sentences:\n","            tokenized_and_filtered_text = [token.lower() for token in nltk.word_tokenize(sent)\n","                                           if token not in \".,?!:;()[]''``*\"]\n","            preprocessed_sentences.append(tokenized_and_filtered_text)\n","        return preprocessed_sentences\n","        #Returns one large list with nested lists that are defined by the given files' sentences.\n","        #Note that certain words (such as \"we'll\") will return as two separate tokens.\n","\n","\n","\n","    #Defining (3) methods to calculate statistics.\n","    def average_word_length(self):\n","        total_number_of_characters = sum(len(word) for word in self.tokenized_text)\n","        total_words = len(self.tokenized_text)\n","        average_length_of_words = total_number_of_characters / total_words\n","        result_string = f'The Average Word Length is {average_length_of_words} letters long.'\n","        return result_string\n","\n","    def type_token_ratio(self):\n","        word_counts = {} #Creating dictionary defined by words (key) and their frequency (value)\n","        for word in self.tokenized_text:\n","            if not word in word_counts:\n","                word_counts[word] = 1\n","            else:\n","                word_counts[word] += 1\n","\n","        #Note how type_counts uses the number of different words (type) and not each word's total freq.\n","        type_count = len([word for word, freq in word_counts.items()])\n","        total_words = len(self.tokenized_text)\n","        type_token_ratio = type_count/total_words\n","        result_string = f'The Type-to-Token Ratio is {type_count}/{total_words} or {type_token_ratio:.2f}.'\n","        #Rounding to two decimals.\n","        return result_string\n","\n","    def hapax_ratio(self):\n","        word_counts = {} #Creating dictionary defined by words (keys) and their frequency (values)\n","        for word in self.tokenized_text:\n","            if not word in word_counts:\n","                word_counts[word] = 1\n","            else:\n","                word_counts[word] += 1\n","\n","        #Note how hapax_count uses the number of different words that occur only once\n","        hapax_count = len([word for word, freq in word_counts.items() if freq == 1])\n","        total_words = len(self.tokenized_text)\n","        hapax_ratio = hapax_count/total_words\n","        result_string = f'The Hapax_Ratio is {hapax_count}/{total_words} or {hapax_ratio:.2f}.'\n","        #Rounding to two decimals.\n","        return result_string\n","\n","    def average_sentence_length(self):\n","        total_words = len(self.tokenized_text)\n","        total_number_of_sentences = len(self.preprocessed_text) #Now using preprocessed_text defined earlier for sentences.\n","        average_sentence_length = total_words/total_number_of_sentences\n","        result_string = f'The average sentence length is {average_sentence_length:.2f} words per sentence.'\n","        #Rounding to two decimals.\n","        return result_string\n","\n","\n","#Executing the Code\n","text_analysis = TextAnalysis('insert filename.txt here')\n","print(text_analysis.average_word_length())\n","print(text_analysis.type_token_ratio())\n","print(text_analysis.hapax_ratio())\n","print(text_analysis.average_sentence_length())\n"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}